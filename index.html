<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
	<head>
          <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-172765096-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-172765096-1');
</script>
		<meta name=viewport content=“width=800”>
		<meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
		<style type="text/css">
			/* Color scheme stolen from Sergey Karayev */
			a {
			color: #008080;
			text-decoration:none;
			}
			a:focus, a:hover {
			color: #008080;
			text-decoration:none;
			}
			body,td,th,tr,p,a {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 13px
			}
			strong {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 13px;
			}
			li {
			margin-bottom: 5px;
			}
			li:last-child {
			margin-bottom: 0px;
			}
			heading {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 20px;
			}
			papertitle {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 13px;
			font-weight: 600
			}
			name {
			font-family: 'Lato', Verdana, Helvetica, sans-serif;
			font-size: 28px;
			}
			.one
			{
			width: 160px;
			height: 160px;
			position: relative;
			}
			.two
			{
			width: 160px;
			height: 160px;
			position: absolute;
			transition: opacity .2s ease-in-out;
			-moz-transition: opacity .2s ease-in-out;
			-webkit-transition: opacity .2s ease-in-out;
			}
			.fade {
			 transition: opacity .2s ease-in-out;
			 -moz-transition: opacity .2s ease-in-out;
			 -webkit-transition: opacity .2s ease-in-out;
			}
			span.highlight {
					background-color: #ffffd0;
			}
		</style>

		<title>Mohamed Lakhal</title>
		<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
		<link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
	</head>


	<body>
		<table width="650" border="0" align="center" cellspacing="0" cellpadding="0">
			<tr>
			<td>
			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
				<tr>
					<td width="67%" valign="middle">
						<p align="center"> <name>Mohamed Ilyes Lakhal</name> </p>
                                                <p>I am a final-year PhD student at Queen Mary University of London, affiliated with the <a href="http://cis.eecs.qmul.ac.uk">Centre for Intelligent Sensing (CIS)</a>.
                                                </p>
                                                <p>Previously, I graduated from <a href="https://www.esi.dz/">Ecole nationale Supérieure d'Informatique (ESI)</a> (Algiers, Algeria) with both a BSc and an MSc.
                                                </p>

						<p align=center>
                                                        <a href="mailto:m.i.lakhal@qmul.ac.uk">Email</a> &nbsp/&nbsp
                                                        <a href="https://scholar.google.com/citations?hl=en&user=eyTk4uoAAAAJ">Google Scholar</a>
						</p>
					</td>
                                        <td width="33%">
                                        <a href="images/profile.jpg">
                                          <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile-circle.png" class="hoverZoomLink"></a>
                                        </td>
				</tr>
			</table>


			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
				<tr>
					<td width="100%" valign="middle">
						<heading>Research</heading>
					</td>
				</tr>

				<tr>
					<td width="100%" valign="middle">
						<papertitle>Novel-View Human Action Synthesis</papertitle>
						<br>
                                                <strong>Mohamed I. Lakhal</strong>, 
                                                <a href="https://scholar.google.co.uk/citations?user=dT1N2IUAAAAJ&hl=en">Davide Boscaini</a>,
                                                <a href="https://scholar.google.co.uk/citations?user=BQ7li6AAAAAJ&hl=en">Fabio Poiesi</a>,
                                                <a href="https://scholar.google.com/citations?user=vpmV4xcAAAAJ&hl=en">Oswald Lanz</a>,
                                                <a href="http://www.eecs.qmul.ac.uk/~andrea/">Andrea Cavallaro</a>
						<br>
						<em>Preprint</em>, 2020
						<br>
						<a href="https://arxiv.org/pdf/2007.02808.pdf">[paper]</a> <a href="https://github.com/mlakhal/gtnet">[code]</a>
                                                <a href="https://mlakhal.github.io/novel-view_action_synthesis.html">[project page]</a>

				</tr>

				<tr>
					<td width="100%" valign="middle">
						<papertitle>View-LSTM: novel-view video synthesis through view decomposition</papertitle>
						<br>
                                                <strong>Mohamed I. Lakhal</strong>, 
                                                <a href="https://scholar.google.com/citations?user=vpmV4xcAAAAJ&hl=en">Oswald Lanz</a>,
                                                <a href="http://www.eecs.qmul.ac.uk/~andrea/">Andrea Cavallaro</a>
						<br>
						<em>International Conference on Computer Vision (ICCV)</em>, 2019
						<br>
						<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Lakhal_View-LSTM_Novel-View_Video_Synthesis_Through_View_Decomposition_ICCV_2019_paper.pdf">[paper]</a> 
				</tr>

				<tr>
					<td width="100%" valign="middle">
						<papertitle>Learnable Masks for Pose-Guided View Synthesis</papertitle>
						<br>
                                                <strong>Mohamed I. Lakhal</strong>, 
                                                <a href="https://scholar.google.com/citations?user=vpmV4xcAAAAJ&hl=en">Oswald Lanz</a>,
                                                <a href="http://www.eecs.qmul.ac.uk/~andrea/">Andrea Cavallaro</a>
						<br>
						<em>IEEE International Conference on Image Processing (ICIP)</em>, 2019
						<br>
						<a href="https://ieeexplore.ieee.org/abstract/document/8803134">[paper]</a> 
				</tr>

				<tr>
					<td width="100%" valign="middle">
						<papertitle>Pose guided human image synthesis by view disentanglement and enhanced weighting loss</papertitle>
						<br>
                                                <strong>Mohamed I. Lakhal</strong>, 
                                                <a href="https://scholar.google.com/citations?user=vpmV4xcAAAAJ&hl=en">Oswald Lanz</a>,
                                                <a href="http://www.eecs.qmul.ac.uk/~andrea/">Andrea Cavallaro</a>
						<br>
						<em>European Conference on Computer Vision (ECCV), HBUGEN Workshop</em>, 2018
						<br>
						<a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11130/Lakhal_Pose_guided_human_image_synthesis_by_view_disentanglement_and_enhanced_ECCVW_2018_paper.pdf">[paper]</a>
					</td>
				</tr>

				<tr>
					<td width="100%" valign="middle">
						<papertitle>Residual Stacked RNNs for Action Recognition</papertitle>
						<br>
                                                <strong>Mohamed I. Lakhal</strong>, 
                                                <a href="https://scholar.google.com/citations?user=n4BtpPsAAAAJ&hl=en">Albert Clapés</a>,
                                                <a href="https://sergioescalera.com/">Sergio Escalera</a>,
                                                <a href="https://scholar.google.com/citations?user=vpmV4xcAAAAJ&hl=en">Oswald Lanz</a>,
                                                <a href="http://www.eecs.qmul.ac.uk/~andrea/">Andrea Cavallaro</a>
						<br>
						<em>European Conference on Computer Vision (ECCV), HBUGEN Workshop</em>, 2018
						<br>
						<a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11130/Lakhal_Residual_Stacked_RNNs_for_Action_Recognition_ECCVW_2018_paper.pdf">[paper]</a>
					</td>
				</tr>

				<tr>
					<td width="100%" valign="middle">
						<papertitle>Recurrent neural networks for remote sensing image classification</papertitle>
						<br>
                                                <strong>Mohamed I. Lakhal</strong>, 
                                                <a href="https://scholar.google.com/citations?user=v0zSSQ0AAAAJ&hl=en">Hakan Cevikalp</a>,
                                                <a href="https://sergioescalera.com/">Sergio Escalera</a>,
                                                <a href="https://scholar.google.com/citations?user=vgFqXEIAAAAJ&hl=en">Ferda Ofli</a>
						<br>
						<em>IET Computer Vision</em>, 2018
						<br>
						<a href="https://ieeexplore.ieee.org/document/8466254">[paper]</a> 
					</td>
				</tr>


				<tr>
					<td width="100%" valign="middle">
						<papertitle>CRN: End-to-end Convolutional Recurrent Network Structure Applied to Vehicle Classification</papertitle>
						<br>
                                                <strong>Mohamed I. Lakhal</strong>, 
                                                <a href="https://sergioescalera.com/">Sergio Escalera</a>,
                                                <a href="https://scholar.google.com/citations?user=v0zSSQ0AAAAJ&hl=en">Hakan Cevikalp</a>
						<br>
						<em> International Conference on Computer Vision Theory and Applications (VISAPP) </em>, 2018
						<br>
						<a href="https://www.scitepress.org/Papers/2018/65336/65336.pdf">[paper]</a>
					</td>
				</tr>
			</table>

			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
				<tr>
					<td>
						<br>
						<p align="right">
							<font size="2">
								<a href="https://anxie.github.io/">website template</a>
								</font>
						</p>
					</td>
				</tr>
			</table>

			</td>
			</tr>
		</table>
	</body>
</html>
